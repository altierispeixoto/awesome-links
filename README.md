# Awesome Links

http://www.homepages.ucl.ac.uk/~ucgtrbd/talks/imperial_causality.pdf

https://www.infoq.com/presentations/stripe-ml-models-fraud/

http://www.cs.cornell.edu/courses/cs7792/2016fa/

http://www.cs.cornell.edu/~adith/CfactSIGIR2016/

https://www.youtube.com/watch?v=QWCSxAKR-h0

https://www.twosigma.com/insights/article/interpretability-methods-in-machine-learning-a-brief-survey/

http://dnc1994.com/2016/05/rank-10-percent-in-first-kaggle-competition-en/
http://www.ke.tu-darmstadt.de/lehre/arbeiten/studien/2015/Dong_Ying.pdf

https://en.wikipedia.org/wiki/Precision_and_recall

### para a palestra
https://www.bbc.com/news/technology-45809919   
https://en.wikipedia.org/wiki/Weapons_of_Math_Destruction   

https://www.infoq.com/br/articles/machine-learning-learn-devops

https://www.infoq.com/articles/book-review-accelerate   

https://enterprisersproject.com/article/2019/2/ai-opportunity-how-to-identify-5-questions-ask  

https://enterprisersproject.com/sites/default/files/an_executives_guide_to_real_world_ai.pdf

##############

https://web.stanford.edu/~jurafsky/slp3/

https://towardsdatascience.com/deep-learning-for-specific-information-extraction-from-unstructured-texts-12c5b9dceada

http://www.ic.unicamp.br/~stolfi/cursos/MC358-2012-1-A/docs/apostila.pdf

https://medium.com/pizzadedados/utilizando-dados-abertos-e-ci%C3%AAncia-de-dados-na-mobilidade-urbana-371a4c591639

https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf

https://machinelearningmastery.com/a-gentle-introduction-to-normality-tests-in-python/
https://machinelearningmastery.com/how-to-transform-data-to-fit-the-normal-distribution/

https://explained.ai/

www.octavian.ai

https://www.youtube.com/watch?v=IeaD0ZaUJ3Y

https://www.thelearningmachine.ai/

https://www.bitfinex.com

https://www.analyticsvidhya.com/blog/2018/09/multivariate-time-series-guide-forecasting-modeling-python-codes/

http://d2l.ai/

http://ccr.sigcomm.org/online/files/p83-keshavA.pdf

https://www.avanwyk.com/an-overview-of-lightgbm/

https://ecomfe.github.io/echarts-doc/public/en/index.html

https://piratepeel.github.io/proximitynetwork.html

https://arxiv.org/pdf/1710.04073.pdf

https://www.lip6.fr/actualite/personnes-fiche.php?ident=P641

https://www.analyticsvidhya.com/blog/2018/05/improve-model-performance-cross-validation-in-python-r/

https://www.analyticsvidhya.com/blog/2016/02/7-important-model-evaluation-error-metrics/

https://www.machinelearningplus.com/machine-learning/evaluation-metrics-classification-models-r/

Hands-On Machine Learning for Algorithmic Trading: Design and implement 

http://mlexplained.com/2018/01/05/lightgbm-and-xgboost-explained/

http://dnc1994.com/2016/05/rank-10-percent-in-first-kaggle-competition-en/

[paperswithcode](https://paperswithcode.com/)

[stanford.edu](https://stanford.edu/~shervine/teaching/)

https://link.springer.com/mwg-internal/de5fs23hu73db/progress?id=vEwZfCNtpsmRUv_3GLjmQ2uA9TANp8FW9irUxJem7wk,&dl

# ML Introduction

[Machine Learning for Everyone](https://vas3k.com/blog/machine_learning/)

[Matemática e Programação para Aprendizado de Máquina](https://matheusfacure.github.io/2017/01/15/pre-req-ml/)

[About Feature Scaling and Normalization – and the effect of standardization for machine learning algorithms](http://sebastianraschka.com/Articles/2014_about_feature_scaling.html#standardization-and-min-max-scaling)

[Processo de Agrupamentos](https://www.maxwell.vrac.puc-rio.br/7975/7975_3.PDF)

[ANÁLISE DE AGRUPAMENTOS](http://www.facom.ufu.br/~backes/pgc204/Aula09-Agrupamentos.pdf)

[How backpropagation works, and how you can use Python to build a neural network](https://medium.freecodecamp.org/build-a-flexible-neural-network-with-backpropagation-in-python-acffeb7846d0)

[Redes Neurais Artificiais](https://www-users.cs.umn.edu/~agoncalv/arquivos/pdfs/redes_neurais.pdf)

[A Visual and Interactive Guide to the Basics of Neural Networks](http://jalammar.github.io/visual-interactive-guide-basics-neural-networks/)

[A Visual And Interactive Look at Basic Neural Network Math](https://jalammar.github.io/feedforward-neural-networks-visual-interactive/)

[Dealing with Imbalanced Classes in Machine Learning](https://towardsdatascience.com/dealing-with-imbalanced-classes-in-machine-learning-d43d6fa19d2)

[8 Tactics to Combat Imbalanced Classes in Your Machine Learning Dataset](https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/)

[Machine Learning Cheatsheet](https://ml-cheatsheet.readthedocs.io/en/latest/index.html)

[A guide for using the Wavelet Transform in Machine Learning](http://ataspinar.com/2018/12/21/a-guide-for-using-the-wavelet-transform-in-machine-learning/)

[A Comprehensive Guide to Ensemble Learning (with Python codes)](https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/)

[A Programmer’s Intuition for Matrix Multiplication](https://betterexplained.com/articles/matrix-multiplication/)

# Data Science Introduction

[Introduction to Correlation](https://www.datascience.com/blog/introduction-to-correlation-learn-data-science-tutorials)

[Introduction to Anomaly Detection](https://www.datascience.com/blog/python-anomaly-detection)

[Implementing a Principal Component Analysis (PCA) – in Python, step by step](http://sebastianraschka.com/Articles/2014_pca_step_by_step.html)

[Principal Component Analysis - Explained Visually](http://setosa.io/ev/principal-component-analysis/)

[Eigenvectors and Eigenvalues - Explained Visually](http://setosa.io/ev/eigenvectors-and-eigenvalues/)

[Significância do Coeficiente de Correlação](http://sisne.org/Disciplinas/Grad/ProbEstat2/aula15.pdf)

[Encoding cyclical continuous features - 24-hour time](https://ianlondon.github.io/blog/encoding-cyclical-features-24hour-time/)



# Deep Learning

[Geometric Deep Learning](http://geometricdeeplearning.com/)

[playground.tensorflow](http://playground.tensorflow.org/)

[Convolutional Neural Networks from the ground up](https://towardsdatascience.com/convolutional-neural-networks-from-the-ground-up-c67bb41454e1)

[A Beginner's Guide To Understanding Convolutional Neural Networks](https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/)

[Build a Recurrent Neural Network from Scratch in Python – An Essential Read for Data Scientists](https://www.analyticsvidhya.com/blog/2019/01/fundamentals-deep-learning-recurrent-neural-networks-scratch-python/)

[Matrix Multiplication in Neural Networks - IMAGE](https://www.datasciencecentral.com/profiles/blogs/matrix-multiplication-in-neural-networks)

[The Matrix Calculus You Need For Deep Learning](https://explained.ai/matrix-calculus/index.html)

[Deep Learning: Which Loss and Activation Functions should I use?](https://towardsdatascience.com/deep-learning-which-loss-and-activation-functions-should-i-use-ac02f1c56aa8)

[Deep Learning Performance Cheat Sheet
Simple and complex tricks that can help you boost your deep learning models accuracy](https://towardsdatascience.com/deep-learning-performance-cheat-sheet-21374b9c4f45)

# Tools

[Autograd](https://github.com/HIPS/autograd)
Autograd can automatically differentiate native Python and Numpy code. It can handle a large subset of Python's features, including loops, ifs, recursion and closures, and it can even take derivatives of derivatives of derivatives. It supports reverse-mode differentiation (a.k.a. backpropagation), which means it can efficiently take gradients of scalar-valued functions with respect to array-valued arguments, as well as forward-mode differentiation, and the two can be composed arbitrarily. The main intended application of Autograd is gradient-based optimization.

[geotrellis](http://geotrellis.io) is a geographic data processing engine for high performance applications.

[geoserver](http://geoserver.org/)  is an open source server for sharing geospatial data. Designed for interoperability, it publishes data from any major spatial data source using open standards.

[geopyspark](https://github.com/locationtech-labs/geopyspark) is a Python bindings library for [GeoTrellis](http://geotrellis.io), a Scala library for working with geospatial data in a distributed environment. By using [PySpark](http://spark.apache.org/docs/latest/api/python/pyspark.html), GeoPySpark is able to provide an interface into the GeoTrellis framework.

[Kepler.gl](http://kepler.gl/#/) is a powerful open source geospatial analysis tool for large-scale data sets.

[LIME](https://github.com/marcotcr/lime) This project is about explaining what machine learning classifiers (or models) are doing. At the moment, we support explaining individual predictions for text classifiers or classifiers that act on tables (numpy arrays of numerical or categorical data) or images, with a package called lime (short for local interpretable model-agnostic explanations). Lime is based on the work presented in this paper (bibtex here for citation). Here is a link to the promo video:

[shap](https://github.com/slundberg/shap) SHAP (SHapley Additive exPlanations) is a unified approach to explain the output of any machine learning model. SHAP connects game theory with local explanations, uniting several previous methods [1-7] and representing the only possible consistent and locally accurate additive feature attribution method based on expectations (see the SHAP NIPS paper for details).

[TransmogrifAI - Automated machine learning for structured data.](https://transmogrif.ai/) TransmogrifAI (pronounced trans-mog-ri-phi) is an end-to-end AutoML library for structured data written in Scala that runs on top of Apache Spark. It was developed with a focus on accelerating machine learning developer productivity through machine learning automation, and an API that enforces compile-time type-safety, modularity, and reuse. Through automation, it achieves accuracies close to hand-tuned models with almost 100x reduction in time. 

[Neupy - Cheat sheet](http://neupy.com/pages/cheatsheet.html) NeuPy is a python library for prototyping and building neural networks. NeuPy uses Tensorflow as a computational backend for deep learning models.

[Hyperopt](http://hyperopt.github.io/hyperopt/) is a Python library for optimizing over awkward search spaces with real-valued, discrete, and conditional dimensions.

[Yellowbrick](http://www.scikit-yb.org/en/latest/) is a suite of visual diagnostic tools called “Visualizers” that extend the Scikit-Learn API to allow human steering of the model selection process. In a nutshell, Yellowbrick combines scikit-learn with matplotlib in the best tradition of the scikit-learn documentation, but to produce visualizations for your models!

[PyOD](https://pyod.readthedocs.io/en/latest/index.html) is a comprehensive and scalable Python toolkit for detecting outlying objects in multivariate data. This exciting yet challenging field is commonly referred as Outlier Detection or Anomaly Detection. Since 2017, PyOD [AZNL19] has been successfully used in various academic researches and commercial products [ARSLS19][AZH18a][AZH18b][AZNHL19]

[LightGBM](https://github.com/Microsoft/LightGBM) A fast, distributed, high performance gradient boosting (GBDT, GBRT, GBM or MART) framework based on decision tree algorithms, used for ranking, classification and many other machine learning tasks. It is under the umbrella of the DMTK(http://github.com/microsoft/dmtk) project of Microsoft.

[mlxtend](http://rasbt.github.io/mlxtend/)(machine learning extensions) is a Python library of useful tools for the day-to-day data science tasks.

[sklearn-deap](https://github.com/rsteca/sklearn-deap) Use evolutionary algorithms instead of gridsearch in scikit-learn. This allows you to exponentially reduce the time required to find the best parameters for your estimator. Instead of trying out every possible combination of parameters, evolve only the combinations that give the best results.

[BayesianOptimization](https://github.com/fmfn/BayesianOptimization)This is a constrained global optimization package built upon bayesian inference and gaussian process, that attempts to find the maximum value of an unknown function in as few iterations as possible. This technique is particularly suited for optimization of high cost functions, situations where the balance between exploration and exploitation is important.

[gplearn](https://gplearn.readthedocs.io/en/stable/intro.html)extends the scikit-learn machine learning library to perform Genetic Programming (GP) with symbolic regression.

[geojson](http://geojson.io)

[AWS Instances](https://www.ec2instances.info)

[floydhub](https://www.floydhub.com/)

[Gpu Analytics Initiative](http://gpuopenanalytics.com/#/)

[MapD - GPU Database](https://www.mapd.com/)

[inspyred](https://pythonhosted.org/inspyred/)

[pagmo2](https://esa.github.io/pagmo2/index.html)

[DEAP](https://deap.readthedocs.io/en/master/)

[scikit-learn](https://scikit-learn.org/)

[scikit-image](https://scikit-image.org/)

[scipy](https://www.scipy.org/)

[tensorflow](https://www.tensorflow.org/)

[keras](https://keras.io/)

[pytorch](https://pytorch.org/)

[numba](http://numba.pydata.org/)

[kepler-mapper](https://kepler-mapper.scikit-tda.org/examples.html)

[rapids](https://rapids.ai/) The RAPIDS suite of open source software libraries gives you the freedom to execute end-to-end data science and analytics pipelines entirely on GPUs. RAPIDS is incubated by NVIDIA® based on years of accelerated data science experience. RAPIDS relies on NVIDIA CUDA® primitives for low-level compute optimization, and exposes GPU parallelism and high-bandwidth memory speed through user-friendly Python interfaces.

https://scikit-multiflow.github.io/

https://moa.cms.waikato.ac.nz/

https://scikit-plot.readthedocs.io/en/stable/Quickstart.html

https://mlbox.readthedocs.io/en/latest/

# Papers
 
[Neural Ordinary Differential Equations](https://github.com/JSeam2/Neural-Ordinary-Differential-Equations)

[Paper Summary: Neural Ordinary Differential Equations](https://towardsdatascience.com/paper-summary-neural-ordinary-differential-equations-37c4e52df128)

[Working with timezones](https://davecturner.github.io/2018/08/12/working-with-timezones.html?utm_source=ActiveCampaign&utm_medium=email&utm_content=BDN+%23135%3A+pop+songs+analysis%2C+the+FiveThirtyEight+algorithm%2C+and+what+makes+Paris+Paris&utm_campaign=Banana+Data+%23135)

[Deep Learning in Neural Networks: An Overview](https://arxiv.org/pdf/1404.7828.pdf)

[Learning Transferable Architectures for Scalable Image Recognition](https://arxiv.org/pdf/1707.07012.pdf)

[A Unified Approach to Interpreting ModelPredictions](http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf)

[“Why Should I Trust You?”Explaining the Predictions of Any Classifier](https://arxiv.org/pdf/1602.04938.pdf)
 
[ANÁLISE E SÍNTESE DE ESTRATÉGIAS DE APRENDIZADO PARA REDES NEURAIS ARTIFICIAIS](ftp://ftp.dca.fee.unicamp.br/pub/docs/vonzuben/theses/lnunes_mest/indice.pdf)

[7 Practical Deep Learning Tips](https://towardsdatascience.com/7-practical-deep-learning-tips-97a9f514100e)

[A Survey of Correlation Clustering](http://www.cs.columbia.edu/~hila/clustering.pdf)

[The Matrix Calculus You Need For Deep Learning](https://arxiv.org/pdf/1802.01528.pdf)

[Fundamentals of Recurrent Neural Network (RNN)
and Long Short-Term Memory (LSTM) Network](https://arxiv.org/pdf/1808.03314.pdf)

[Math behind CNN](https://arxiv.org/pdf/1802.01528.pdf)


[DEEP CONVOLUTIONAL NEURAL NETWORK DESIGN PATTERNS](https://arxiv.org/pdf/1611.00847v2.pdf)

# Books

[Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/)

[Feature Engineering](http://www.feat.engineering/)

[The Elements ofStatistical Learning](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)

[Understanding Machine Learning:From Theory to Algorithms](http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf)

[Introduction to Probability](https://www.dartmouth.edu/~chance/teaching_aids/books_articles/probability_book/amsbook.mac.pdf)

[deeplearningbook.com.br](http://deeplearningbook.com.br/capitulos/)

[Algorithms for Clustering Data](https://homepages.inf.ed.ac.uk/rbf/BOOKS/JAIN/Clustering_Jain_Dubes.pdf)

[neuralnetworksanddeeplearning.com](http://neuralnetworksanddeeplearning.com/chap1.html)

[deeplearningbook.org](http://www.deeplearningbook.org/)

[Machine Learning Yarning - Andrew Ng](https://d2wvfoqc9gyqzf.cloudfront.net/content/uploads/2018/09/Ng-MLY01-13.pdf)

[Foundations of Data Science](https://www.cs.cornell.edu/jeh/book.pdf)

[Fundamentals of Data Visualization](https://serialmentor.com/dataviz/)

[Feature Engineering and Selection: A Practical Approach for Predictive Models](http://www.feat.engineering/)

[Dive into Deep Learning](http://d2l.ai)

[Forecasting: Principles and Practice](https://otexts.com/fpp2/)

# Courses

[fast.ai](http://course18.fast.ai/)

[Essential Math for Machine Learning: Python Edition](https://www.edx.org/course/essential-math-for-machine-learning-python-edition)

[Machine Learning Crash Course: with TensorFlow APIs](https://developers.google.com/machine-learning/crash-course/)

[# Optimization Theory](https://www.math.uh.edu/~rohop/fall_06/)

[Introduction to Deep Learning: MIT's introductory course on deep learning methods and applications.](http://introtodeeplearning.com/)

[Dremio University](https://university.dremio.com/)

[kaggle - Machine Learning Explainability](https://www.kaggle.com/learn/machine-learning-explainability)

[kaggle - Machine Learning](https://www.kaggle.com/learn/machine-learning/)

[kaggle - Deep Learning](https://www.kaggle.com/learn/deep-learning)

[kaggle - Embeddings](https://www.kaggle.com/learn/embeddings)

# Datasets

[geodata-br](https://github.com/tbrugz/geodata-br)

[Stanford Large Network Dataset Collection](https://snap.stanford.edu/data/)

# Markov Chains

[Markov Chains in Python: Beginner Tutorial](https://www.datacamp.com/community/tutorials/markov-chains-python-tutorial)

[Markov Chains](http://setosa.io/ev/markov-chains/)

[Processos de Decisão de Markov: um tutorial](http://www.seer.ufrgs.br/rita/article/viewFile/rita_v14_n2_p133-179/3544)

[The 50 Best Public Datasets for Machine Learning](https://medium.com/datadriveninvestor/the-50-best-public-datasets-for-machine-learning-d80e9f030279)

# Graph Mining

[Anomaly, Event, and Fraud Detection in Large Graph Datasets](https://www.andrew.cmu.edu/user/lakoglu/wsdm13/)


# Optimization
[A birds-eye view of optimization algorithms](http://fa.bianp.net/teaching/2018/eecs227at/)

[Solving the knapsack problem with a simple genetic algorithm](https://www.dataminingapps.com/2017/03/solving-the-knapsack-problem-with-a-simple-genetic-algorithm/)

--------------------------------

# Cases

## Pricing 

[The Price is Right: Pricing Strategy — Part 1](https://towardsdatascience.com/the-price-is-right-pricing-strategy-part-1-d4952dc5f5dd)

[Machine Learning for Retail Price Recommendation with Python](https://towardsdatascience.com/machine-learning-for-retail-price-suggestion-with-python-64531e64186d)

[Developing a Pricing Strategy to Maximize Revenue](https://www.datascience.com/resources/notebooks/python-dynamic-pricing)


## Churning

[Introduction to Churn Prediction in Python](https://www.datascience.com/blog/churn-prediction-python)


## Fraud Detection

https://www.datascience.com/blog/fraud-detection-with-tensorflow

https://towardsdatascience.com/bayes-theorem-the-holy-grail-of-data-science-55d93315defb



## TODO : CLASSIFY

https://medium.com/@zhanwenchen/install-cuda-and-cudnn-for-tensorflow-gpu-on-ubuntu-79306e4ac04e

https://github.com/deepmind/graph_nets

https://arxiv.org/pdf/1806.01261.pdf

https://arxiv.org/pdf/1712.09926.pdf

https://www.kaggle.com/kmader/inceptionv3-for-retinopathy-gpu-hr

https://bigdl-project.github.io/

https://tensorspace.org

http://www2.cs.uregina.ca/~dbd/cs831/notes/neural-networks/neuroevolution/
http://www2.cs.uregina.ca/~dbd/cs831/notes/neural-networks/conv-neural-networks/


Estatística
http://greenteapress.com/thinkstats2/thinkstats2.pdf  
https://github.com/AllenDowney/ThinkStats2  



https://pt.wikipedia.org/wiki/Quarteto_de_Anscombe

https://paulovasconcellos.com.br/10-bibliotecas-de-data-science-para-python-que-ningu%C3%A9m-te-conta-706ec3c4fcef

https://seeing-theory.brown.edu/

https://towardsdatascience.com/the-5-basic-statistics-concepts-data-scientists-need-to-know-2c96740377ae

https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/machine_learning.html

https://www.analyticsvidhya.com/blog/2016/03/practical-guide-deal-imbalanced-classification-problems/

https://www.analyticsvidhya.com/blog/2018/10/understanding-inception-network-from-scratch/

https://www.analyticsvidhya.com/blog/2018/10/comprehensive-overview-machine-learning-part-1/

https://www.analyticsvidhya.com/blog/2018/09/multivariate-time-series-guide-forecasting-modeling-python-codes/

https://www.analyticsvidhya.com/blog/2018/10/introduction-neural-networks-deep-learning/

https://physics.bu.edu/~pankajm/MLnotebooks.html

http://www.cs.utsa.edu/~bylander/cs6243/cohen95ripper.pdf

https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf



[How Convolutional Neural Networks learn](https://towardsdatascience.com/convolutional-neural-networks-from-the-ground-up-c67bb41454e1)

https://hackernoon.com/50-data-structure-and-algorithms-interview-questions-for-programmers-b4b1ac61f5b0

[neural network embeddings explained](https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526)

[why momentum really works](https://distill.pub/2017/momentum/)

[building autoencoders in keras](https://blog.keras.io/building-autoencoders-in-keras.html)

[A Practical guide to Autoencoders](https://sadanand-singh.github.io/posts/autoencoders/)


http://aqibsaeed.github.io

http://karpathy.github.io/2016/05/31/rl/


[Where did the least-square come from?](https://towardsdatascience.com/where-did-the-least-square-come-from-3f1abc7f7caf)

[An End-to-End Guide to Understand the Math behind XGBoost](https://www.analyticsvidhya.com/blog/2018/09/an-end-to-end-guide-to-understand-the-math-behind-xgboost/)

[A -Deviation Density Based Clustering Algorithm](https://www.hindawi.com/journals/mpe/2018/3742048/)

[DBCV - Python implementation of Density-Based Clustering Validation](https://github.com/christopherjenness/DBCV)



https://www.youtube.com/watch?v=6HI47rcOiAE


https://support.minitab.com/pt-br/minitab/18/help-and-how-to/statistics/basic-statistics/supporting-topics/basics/linear-nonlinear-and-monotonic-relationships/

https://www.imperial.ac.uk/media/imperial-college/administration-and-support-services/enterprise-office/public/Table-of-Disruptive-Technologies.pdf?fbclid=IwAR0_lHxpYov7DzeFOfrJKWAOBAYikfkE-Uzzf3FVFwYs7XpXyHa7MOel2tQ

https://www.linkedin.com/pulse/deeptech-ai-drug-discovery-margaretta-colangelo/



https://labs.spotify.com/2014/09/16/squad-health-check-model/


http://revista.usereserva.com/2016/01/05/decida-como-voce-quer-viver/

[Os Tipos de Engenheiros de Dados](https://medium.com/data-hackers/os-tipos-de-engenheiros-de-dados-c3674b4d74d1)

http://bytepawn.com/

[24 Ultimate Data Science Projects To Boost Your Knowledge and Skills (& can be accessed freely)](https://www.analyticsvidhya.com/blog/2018/05/24-ultimate-data-science-projects-to-boost-your-knowledge-and-skills/)

https://www.youtube.com/watch?v=EUQY3hL38cw -- hierarquical clustering  

https://www.youtube.com/watch?v=3vHqmPF4VBA -- k-means  

https://distill.pub/

https://medium.com/@Chamanijks/k-prototype-in-clustering-mixed-attributes-e6907db91914

https://resources.zilliant.com/authors/amir-meimand

https://towardsdatascience.com/maximum-likelihood-estimation-in-real-life-optimizing-study-time-d5cc083d25b4


http://jmlr.org/papers/volume10/tuv09a/tuv09a.pdf

http://dnc1994.com/2016/05/rank-10-percent-in-first-kaggle-competition-en/

https://robjhyndman.com/papers/mase.pdf




























 

 
 




 
 
 








 






 

