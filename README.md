# Awesome Links


# ML Introduction

[Machine Learning for Everyone](https://vas3k.com/blog/machine_learning/)

[Matemática e Programação para Aprendizado de Máquina](https://matheusfacure.github.io/2017/01/15/pre-req-ml/)

[About Feature Scaling and Normalization – and the effect of standardization for machine learning algorithms](http://sebastianraschka.com/Articles/2014_about_feature_scaling.html#standardization-and-min-max-scaling)

[Processo de Agrupamentos](https://www.maxwell.vrac.puc-rio.br/7975/7975_3.PDF)

[ANÁLISE DE AGRUPAMENTOS](http://www.facom.ufu.br/~backes/pgc204/Aula09-Agrupamentos.pdf)

[How backpropagation works, and how you can use Python to build a neural network](https://medium.freecodecamp.org/build-a-flexible-neural-network-with-backpropagation-in-python-acffeb7846d0)

[Redes Neurais Artificiais](https://www-users.cs.umn.edu/~agoncalv/arquivos/pdfs/redes_neurais.pdf)

[A Visual and Interactive Guide to the Basics of Neural Networks](http://jalammar.github.io/visual-interactive-guide-basics-neural-networks/)

[# A Visual And Interactive Look at Basic Neural Network Math](https://jalammar.github.io/feedforward-neural-networks-visual-interactive/)

[Dealing with Imbalanced Classes in Machine Learning](https://towardsdatascience.com/dealing-with-imbalanced-classes-in-machine-learning-d43d6fa19d2)

[Machine Learning Cheatsheet](https://ml-cheatsheet.readthedocs.io/en/latest/index.html)

# Deep Learning

[Geometric Deep Learning](http://geometricdeeplearning.com/)

# Tools

[Autograd](https://github.com/HIPS/autograd)
Autograd can automatically differentiate native Python and Numpy code. It can handle a large subset of Python's features, including loops, ifs, recursion and closures, and it can even take derivatives of derivatives of derivatives. It supports reverse-mode differentiation (a.k.a. backpropagation), which means it can efficiently take gradients of scalar-valued functions with respect to array-valued arguments, as well as forward-mode differentiation, and the two can be composed arbitrarily. The main intended application of Autograd is gradient-based optimization.


[geotrellis](http://geotrellis.io) is a geographic data processing engine for high performance applications.

[geoserver](http://geoserver.org/)  is an open source server for sharing geospatial data. Designed for interoperability, it publishes data from any major spatial data source using open standards.

[geopyspark](https://github.com/locationtech-labs/geopyspark) is a Python bindings library for [GeoTrellis](http://geotrellis.io), a Scala library for working with geospatial data in a distributed environment. By using [PySpark](http://spark.apache.org/docs/latest/api/python/pyspark.html), GeoPySpark is able to provide an interface into the GeoTrellis framework.

[Kepler.gl](http://kepler.gl/#/) is a powerful open source geospatial analysis tool for large-scale data sets.

[LIME](https://github.com/marcotcr/lime)

[shap](https://github.com/slundberg/shap)

[TransmogrifAI - Automated machine learning for structured data.](https://transmogrif.ai/)

[Gpu Analytics Initiative](http://gpuopenanalytics.com/#/)

[MapD - GPU Database](https://www.mapd.com/)

[Neupy - Cheat sheet](http://neupy.com/pages/cheatsheet.html)

[Hyperopt](http://hyperopt.github.io/hyperopt/)

[Yellowbrick](http://www.scikit-yb.org/en/latest/)

[PyOD](https://pyod.readthedocs.io/en/latest/index.html)

# Papers
 
[Neural Ordinary Differential Equations](https://github.com/JSeam2/Neural-Ordinary-Differential-Equations)

[Paper Summary: Neural Ordinary Differential Equations](https://towardsdatascience.com/paper-summary-neural-ordinary-differential-equations-37c4e52df128)

[Working with timezones](https://davecturner.github.io/2018/08/12/working-with-timezones.html?utm_source=ActiveCampaign&utm_medium=email&utm_content=BDN+%23135%3A+pop+songs+analysis%2C+the+FiveThirtyEight+algorithm%2C+and+what+makes+Paris+Paris&utm_campaign=Banana+Data+%23135)

[Deep Learning in Neural Networks: An Overview](https://arxiv.org/pdf/1404.7828.pdf)

[Learning Transferable Architectures for Scalable Image Recognition](https://arxiv.org/pdf/1707.07012.pdf)

[A Unified Approach to Interpreting ModelPredictions](http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf)

[“Why Should I Trust You?”Explaining the Predictions of Any Classifier](https://arxiv.org/pdf/1602.04938.pdf)
 
 [ANÁLISE E SÍNTESE DE ESTRATÉGIAS DEAPRENDIZADO PARA REDES NEURAIS ARTIFICIAIS](ftp://ftp.dca.fee.unicamp.br/pub/docs/vonzuben/theses/lnunes_mest/indice.pdf)

[Implementing a Principal Component Analysis (PCA) – in Python, step by step](http://sebastianraschka.com/Articles/2014_pca_step_by_step.html)

[Principal Component Analysis - Explained Visually](http://setosa.io/ev/principal-component-analysis/)

[7 Practical Deep Learning Tips](https://towardsdatascience.com/7-practical-deep-learning-tips-97a9f514100e)

[Eigenvectors and Eigenvalues - Explained Visually](http://setosa.io/ev/eigenvectors-and-eigenvalues/)

[Significância do Coeficiente de Correlação](http://sisne.org/Disciplinas/Grad/ProbEstat2/aula15.pdf)

[A Survey of Correlation Clustering](http://www.cs.columbia.edu/~hila/clustering.pdf)

[The Matrix Calculus You Need For Deep Learning](https://arxiv.org/pdf/1802.01528.pdf)

[Fundamentals of Recurrent Neural Network (RNN)
and Long Short-Term Memory (LSTM) Network](https://arxiv.org/pdf/1808.03314.pdf)

# Books

[Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/)

[Feature Engineering](http://www.feat.engineering/)

[The Elements ofStatistical Learning](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)

[Understanding Machine Learning:From Theory to Algorithms](http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf)

[Introduction to Probability](https://www.dartmouth.edu/~chance/teaching_aids/books_articles/probability_book/amsbook.mac.pdf)

[deeplearningbook.com.br](http://deeplearningbook.com.br/capitulos/)

[Algorithms for Clustering Data](https://homepages.inf.ed.ac.uk/rbf/BOOKS/JAIN/Clustering_Jain_Dubes.pdf)

[neuralnetworksanddeeplearning.com](http://neuralnetworksanddeeplearning.com/chap1.html)

[deeplearningbook.org](http://www.deeplearningbook.org/)

[Machine Learning Yarning - Andrew Ng](https://d2wvfoqc9gyqzf.cloudfront.net/content/uploads/2018/09/Ng-MLY01-13.pdf)

# Courses

[fast.ai](http://course18.fast.ai/)

[Essential Math for Machine Learning: Python Edition](https://www.edx.org/course/essential-math-for-machine-learning-python-edition)

[Machine Learning Crash Course: with TensorFlow APIs](https://developers.google.com/machine-learning/crash-course/)

[# Optimization Theory](https://www.math.uh.edu/~rohop/fall_06/)

[Introduction to Deep Learning: MIT's introductory course on deep learning methods and applications.](http://introtodeeplearning.com/)



# Datasets

[geodata-br](https://github.com/tbrugz/geodata-br)


## TODO

[playground.tensorflow](http://playground.tensorflow.org/)

https://www.youtube.com/watch?v=6HI47rcOiAE

[Introduction to Correlation](https://www.datascience.com/blog/introduction-to-correlation-learn-data-science-tutorials)

[Introduction to Anomaly Detection](https://www.datascience.com/blog/python-anomaly-detection)



http://geojson.io

### AWS Instances 
https://www.ec2instances.info

https://www.datasciencecentral.com/profiles/blogs/matrix-multiplication-in-neural-networks


https://support.minitab.com/pt-br/minitab/18/help-and-how-to/statistics/basic-statistics/supporting-topics/basics/linear-nonlinear-and-monotonic-relationships/

https://www.imperial.ac.uk/media/imperial-college/administration-and-support-services/enterprise-office/public/Table-of-Disruptive-Technologies.pdf?fbclid=IwAR0_lHxpYov7DzeFOfrJKWAOBAYikfkE-Uzzf3FVFwYs7XpXyHa7MOel2tQ

https://www.linkedin.com/pulse/deeptech-ai-drug-discovery-margaretta-colangelo/

https://www.analyticsvidhya.com/blog/2019/01/fundamentals-deep-learning-recurrent-neural-networks-scratch-python/


https://ianlondon.github.io/blog/encoding-cyclical-features-24hour-time/

https://labs.spotify.com/2014/09/16/squad-health-check-model/

https://towardsdatascience.com/convolutional-neural-networks-from-the-ground-up-c67bb41454e1

https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/

[Markov Chains in Python: Beginner Tutorial](https://www.datacamp.com/community/tutorials/markov-chains-python-tutorial)

[Markov Chains](http://setosa.io/ev/markov-chains/)


http://revista.usereserva.com/2016/01/05/decida-como-voce-quer-viver/

[Os Tipos de Engenheiros de Dados](https://medium.com/data-hackers/os-tipos-de-engenheiros-de-dados-c3674b4d74d1)

http://bytepawn.com/

[24 Ultimate Data Science Projects To Boost Your Knowledge and Skills (& can be accessed freely)](https://www.analyticsvidhya.com/blog/2018/05/24-ultimate-data-science-projects-to-boost-your-knowledge-and-skills/)

https://www.youtube.com/watch?v=EUQY3hL38cw -- hierarquical clustering  

https://www.youtube.com/watch?v=3vHqmPF4VBA -- k-means  

https://distill.pub/

https://medium.com/@Chamanijks/k-prototype-in-clustering-mixed-attributes-e6907db91914

https://resources.zilliant.com/authors/amir-meimand

https://towardsdatascience.com/maximum-likelihood-estimation-in-real-life-optimizing-study-time-d5cc083d25b4


--------------------------------


https://www.datascience.com/blog/churn-prediction-python

https://www.datascience.com/blog/fraud-detection-with-tensorflow

https://towardsdatascience.com/bayes-theorem-the-holy-grail-of-data-science-55d93315defb

https://www.datascience.com/resources/notebooks/python-dynamic-pricing

https://serialmentor.com/dataviz/

https://explained.ai/matrix-calculus/index.html

https://www.cs.cornell.edu/jeh/book.pdf

http://ataspinar.com/2018/12/21/a-guide-for-using-the-wavelet-transform-in-machine-learning/

http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf

http://www.deeplearningbook.org/

https://christophm.github.io/interpretable-ml-book/

http://fa.bianp.net/teaching/2018/eecs227at/

https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html

https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/

https://www.business-science.io/business/2017/11/28/customer_churn_analysis_keras.html

https://snap.stanford.edu/data/

https://medium.com/datadriveninvestor/the-50-best-public-datasets-for-machine-learning-d80e9f030279

https://towardsdatascience.com/the-price-is-right-pricing-strategy-part-1-d4952dc5f5dd

https://towardsdatascience.com/machine-learning-for-retail-price-suggestion-with-python-64531e64186d

https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/

https://betterexplained.com/articles/matrix-multiplication/

https://paperswithcode.com/

http://www.datasus.gov.br/cid10/V2008/cid10.htm

https://www.reddit.com/r/dataisbeautiful/comments/a4l0ta/the_unit_circle_oc/?st=JPILFYS2&sh=250ef731

http://cs231n.github.io/

https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks#

https://towardsdatascience.com/deep-learning-performance-cheat-sheet-21374b9c4f45

https://towardsdatascience.com/deep-learning-which-loss-and-activation-functions-should-i-use-ac02f1c56aa8

http://www.feat.engineering/

https://www.floydhub.com

https://github.com/pandas-profiling/pandas-profiling

https://medium.com/@rogerxujiang/setting-up-a-gpu-instance-for-deep-learning-on-aws-795343e16e44

https://medium.com/@zhanwenchen/install-cuda-and-cudnn-for-tensorflow-gpu-on-ubuntu-79306e4ac04e

https://github.com/deepmind/graph_nets

https://arxiv.org/pdf/1806.01261.pdf

https://arxiv.org/pdf/1712.09926.pdf

https://www.kaggle.com/kmader/inceptionv3-for-retinopathy-gpu-hr

https://bigdl-project.github.io/

https://tensorspace.org

http://www2.cs.uregina.ca/~dbd/cs831/notes/neural-networks/neuroevolution/
http://www2.cs.uregina.ca/~dbd/cs831/notes/neural-networks/conv-neural-networks/


Estatística
http://greenteapress.com/thinkstats2/thinkstats2.pdf  
https://github.com/AllenDowney/ThinkStats2  



https://pt.wikipedia.org/wiki/Quarteto_de_Anscombe

https://paulovasconcellos.com.br/10-bibliotecas-de-data-science-para-python-que-ningu%C3%A9m-te-conta-706ec3c4fcef

https://seeing-theory.brown.edu/

https://towardsdatascience.com/the-5-basic-statistics-concepts-data-scientists-need-to-know-2c96740377ae

https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/machine_learning.html

https://www.analyticsvidhya.com/blog/2016/03/practical-guide-deal-imbalanced-classification-problems/

https://www.analyticsvidhya.com/blog/2018/10/understanding-inception-network-from-scratch/

https://www.analyticsvidhya.com/blog/2018/10/comprehensive-overview-machine-learning-part-1/

https://www.analyticsvidhya.com/blog/2018/09/multivariate-time-series-guide-forecasting-modeling-python-codes/

https://www.analyticsvidhya.com/blog/2018/10/introduction-neural-networks-deep-learning/

https://physics.bu.edu/~pankajm/MLnotebooks.html

http://www.cs.utsa.edu/~bylander/cs6243/cohen95ripper.pdf

https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf

[Math behind CNN](https://arxiv.org/pdf/1802.01528.pdf)

[How Convolutional Neural Networks learn](https://towardsdatascience.com/convolutional-neural-networks-from-the-ground-up-c67bb41454e1)

https://hackernoon.com/50-data-structure-and-algorithms-interview-questions-for-programmers-b4b1ac61f5b0

[neural network embeddings explained](https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526)

[why momentum really works](https://distill.pub/2017/momentum/)

[building autoencoders in keras](https://blog.keras.io/building-autoencoders-in-keras.html)

[A Practical guide to Autoencoders](https://sadanand-singh.github.io/posts/autoencoders/)


http://aqibsaeed.github.io

http://karpathy.github.io/2016/05/31/rl/

[Processos de Decisão de Markov: um tutorial](http://www.seer.ufrgs.br/rita/article/viewFile/rita_v14_n2_p133-179/3544)

[Where did the least-square come from?](https://towardsdatascience.com/where-did-the-least-square-come-from-3f1abc7f7caf)

[An End-to-End Guide to Understand the Math behind XGBoost](https://www.analyticsvidhya.com/blog/2018/09/an-end-to-end-guide-to-understand-the-math-behind-xgboost/)

[A -Deviation Density Based Clustering Algorithm](https://www.hindawi.com/journals/mpe/2018/3742048/)

[DBCV - Python implementation of Density-Based Clustering Validation](https://github.com/christopherjenness/DBCV)

[DEEP CONVOLUTIONAL NEURAL NETWORK DESIGN PATTERNS](https://arxiv.org/pdf/1611.00847v2.pdf)

[Anomaly, Event, and Fraud Detection in Large Graph Datasets](https://www.andrew.cmu.edu/user/lakoglu/wsdm13/)





 


















 




























 

 
 




 
 
 








 






 

